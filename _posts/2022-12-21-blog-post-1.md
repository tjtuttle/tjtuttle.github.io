---
title: 'Lessons from Spark and beyond'
date: 2022-12-21
permalink: /posts/2022/12/blog-post-1
tags:

---
### Background
This quarter we updated a programming assignment (PA) which dealt with PySpark, teaching students to deploy large-scale analytics using this API. The PA’s original workflow involved a Spark Image provided to the students. This image detailed how the Spark cluster would deploy on UCSD’s Data Science and Machine Learning Platform ([DSMLP](https://datahub.ucsd.edu/)) for the students to use. The approach sometimes caused issues as students attempted to modify their image to improve their cluster provisions (e.g., 4 CPUs instead of 3 CPUs). It was decided to modify the PA structure such that upon deployment of a student’s account on DSMLP, a Spark image would automatically run. This had numerous advantages, including more equitable allocation of resources, easier PA grading, and allowing students to focus on improving their code instead of modifying the image.

### The Problem
This change effectively abstracted the spark-master from the end user, allowing for guaranteed consistency between each student’s setup. Deploying this onto DSMLP was another challenge altogether, as the system for DSMLP was not customizable by the end user. Any environment variables had to be set by the DSMLP team. Furthermore, the image for the spark cluster was now hosted on DSMLP and distributed to each student from their end. We encountered errors of varying degrees of severity. We faced issues where the dataset would not connect to the workers, or the workers would not accept jobs from the Spark-Master. Additionally, there were cases where code would work on one account but not on others.

![DMSLP and its setup](./images/dsmlp_setup.jpg)

### The Solution
The first issue we encountered was that we needed to mount the dataset, which needs to be done so that it can be accessed by each of the spark-workers in a cluster. After that was done, it was a matter of updating the image to the same version of Spark that was hosted on DSMLP. The version we were using was a bit behind, so the syntax for the image needed to be changed so that the cluster would deploy. Lastly, we ensured that all other dependencies the students might use (like Koalas) for the assignment ran properly. This issue was particularly interesting, as the environments set up by DSMLP for each student were slightly different due to the individual nature of the accounts, causing some students to have working code while others did not. We were able to configure the accounts enrolled in the course to launch the same environment, with the same spark image, on the same dataset.

### Conclusion
Huge thanks to the DSMLP team for being so responsive and helping us get this resolved. This took a good 60 hours of my time, and though it caused a slight delay in releasing the PA, this experience made me very familiar with Spark, Kubernetes, and their inner workings.
