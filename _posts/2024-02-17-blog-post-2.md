---
title: "Deploying ML Isn't Always Easy"
date: 2024-02-17
permalink: /posts/2024/02/blog-post-2
tags:

---
In the rapidly evolving world of financial technology, machine learning (ML) is becoming an indispensable tool for developing innovative solutions. One of the most pressing applications is in the creation of alternative credit systems, which aim to provide loans to individuals who do not have access to traditional credit. After working closely with an ML team tasked with deploying such a system on a large scale, a few lessons I have learned are discussed here. 

### Understanding the Problem Space

Before diving into the technical aspects, it's crucial to understand the problem. Traditional credit systems rely heavily on credit scores, which are often unavailable or insufficient for large segments of the population. For those without credit scores, it is difficult for banks to ascertain the risk of an individual, as such they often are unable to get loans altogether. Particularly true in developing regions, where many individuals are "credit invisible." The goal of an alternative credit system is to use ML algorithms to analyze non-traditional data sources—such as utility payments, mobile phone usage, and social media activity—to assess creditworthiness so that these people can get loans.

### Challenges in Large-Scale Deployment

Deploying an ML-driven credit system at scale comes with challenges that require careful consideration and strategic planning.
The first major challenge is data. Much of the data sources used in this system are often unstructured and heterogeneous. Integrating these diverse data types into a cohesive model requires a lot of data preprocessing and feature engineering. Ensuring the quality and reliability of this data is crucial, as any inaccuracies can lead to biased credit decisions which we ant to avoid. One of the primary concerns in deploying ML models for credit scoring is ensuring that the models are both interpretable and fair. In financial services, regulatory scrutiny is high, and the implications of a model's decisions can be life-changing for individuals. Therefore, the models must be transparent, providing clear explanations for why certain individuals are deemed creditworthy while others are not.  Additionally, the models must be rigorously tested to ensure they do not inadvertently perpetuate biases or discriminate against specific groups within the confines of the law. As the system is deployed on a large scale, it must be capable of processing vast amounts of data in real-time or near-real-time. Ensuring low-latency predictions while maintaining high accuracy is important, where one can afford it is recommended to create infrastructure suited to the specific needs of the task. The system must adhere to strict data privacy laws, financial regulations in each jurisdiction where it is deployed, which includes ensuring that personal data is securely stored as well as transmitted and that the models comply with all relevant legal standards. Additionally, the system must be robust against cyber threats, as the financial sector is a prime target for malicious actors.

### Strategies for Deployment

Instead of attempting to build a perfect model from the start, adopting an iterative approach allows for continuous improvement. By deploying the model in stages and gradually expanding its scope, the team can gather real-world feedback and refine the model accordingly. Successful deployment requires close collaboration between data scientists, engineers, legal experts, and domain specialists. This cross-functional approach ensures that all aspects of the system, from technical performance to legal compliance, are addressed holistically. Post-deployment, continuous monitoring of the model's performance is essential. Batching the gradient descent done, and then making the system fault- tolerant can go along way in maintaining accuracy. The question is not if a computer will fail in a large system, but when. Track key metrics such as fairness, and system latency, as well as being prepared to adapt the model in response to changes in data patterns or regulatory requirements. For large systems built in fault tolerance is essential and should be implemented from the beginning. Designing systems around the task is imperative, using GPUs or TPUs for the inference to allow the end user to enjoy low latency is recommended. 

### Conclusion

Deploying an ML-driven alternative credit system at scale is a challenging endeavor, as is most ML systems at scale. By focusing on data quality, model fairness, scalability, regulatory compliance, and adopting iterative development, it is possible to build a system that both meets technical requirements and can also has a meaningful impact on financial inclusion. Guiding an ML team through this process has been an enriching experience, offering insights into the intersection of technology, finance, and social good.
